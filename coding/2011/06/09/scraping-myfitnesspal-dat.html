<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><title>Scraping data from MyFitnessPal with python</title><meta name=description content="I am Dr Martin Chorley. I am a lecturer at the School of Computer Science & Informatics, Cardiff University.I'm programme leader for the MSc in Computational Journalism, and also senior personal tutor for all taught postgraduate students. I mainly do work that falls under the umbrella of the Mobile and Social Computing group.
"><link rel=icon href=/img/favicon.png><link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" rel=stylesheet type=text/css><link rel=stylesheet type=text/css href=/css/main.css></head><body><div class=wrapper><div class=post><a class=post__back href=/ >&lt;-- back</a><h1 class=post__title>Scraping data from MyFitnessPal with python</h1><p class=post__date>June 9, 2011</p><div class=post__content ?><p>Following my <a href=http://users.cs.cf.ac.uk/M.J.Chorley/2011/06/07/web-search-wordle/ >success</a> with <a href=http://users.cs.cf.ac.uk/M.J.Chorley/2011/06/05/google-web-history/ >extracting</a> my Google Search History in a simple manner, I’ve decided that I should do something similar to extract all the data I’ve been feeding into <a href=http://www.myfitnesspal.com>myfitnesspal</a> for the last 5 months. As I briefly mentioned in the <a href=http://users.cs.cf.ac.uk/M.J.Chorley/2011/06/07/reviewmfp/ >review of the app + website</a>, the progress graphs leave a lot to be desired and there’s very little in the way of analysis of the data. I have a lot of questions about my progress and there is no easy way to answer all of them using just the website. For instance, what is my average sugar intake? Is this more or less than my target intake? How does my weekend nutrition compare to my weekday nutrition? How much beer have I drunk since starting to log all my food?</p><p>Unfortunately there isn’t an API for the website yet, so I’m going to need to resort to screen scraping to extract it all. This should be pretty easy using the <a href=http://www.crummy.com/software/BeautifulSoup/ >BeautifulSoup</a> python library, but first I need to get access to the data. My food diary isn’t public, so I need to be logged in to get access to it. This means my scraping script needs to pretend to be a web browser and log me in to the website in order to access the pages I need.</p><p>I initially toyed with the idea of reading cookies from the web browser sqlite cookie database, but this is overly complex. It’s actually much easier just using python to do the login as a POST request and to store any cookies received back from that. Fortunately I’m not the first person to try and do this, so there’s <a href=http://stackoverflow.com/questions/2954381/python-form-post-using-urllib2-also-question-on-saving-using-cookies>plenty</a> of <a href=http://stackoverflow.com/questions/301924/python-urllib-urllib2-httplib-confusion>examples</a> on <a href=http://www.stackoverflow.com>StackOverflow</a> of how to do it. I’ll post my own solution once it’s done.</p></div></div></div></body></html>