<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Api on Martin Chorley</title>
    <link>/tags/api/</link>
    <description>Recent content in Api on Martin Chorley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Wed, 19 Nov 2014 12:13:11 +0000</lastBuildDate>
    
	<atom:link href="/tags/api/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Quick and Dirty Twitter API in Python</title>
      <link>/2014/11/19/quick-and-dirty-twitter-api-in-python/</link>
      <pubDate>Wed, 19 Nov 2014 12:13:11 +0000</pubDate>
      
      <guid>/2014/11/19/quick-and-dirty-twitter-api-in-python/</guid>
      <description>QUICK DISCLAIMER: this is a quick and dirty solution to a problem, so may not represent best coding practice, and has absolutely no error checking or handling. Use with caution&amp;hellip;
A recent project has needed me to scrape some data from Twitter. I considered using Tweepy, but as it was a project for the MSc in Computational Journalism, I thought it would be more interesting to write our own simple Twitter API wrapper in Python.</description>
    </item>
    
    <item>
      <title>Foursquare icon downloading (yet again)</title>
      <link>/2014/08/01/foursquare-icon-downloading-yet-again/</link>
      <pubDate>Fri, 01 Aug 2014 07:14:16 +0000</pubDate>
      
      <guid>/2014/08/01/foursquare-icon-downloading-yet-again/</guid>
      <description>Previously I&amp;rsquo;vewritten about a little script to download all the category icons from Foursquare and to create many different coloured versions of them. I&amp;rsquo;ve recently had to do this again for a project, and found my previous script did not work with a recent API version. I&amp;rsquo;ve updated the script to fix it and put it up on github.</description>
    </item>
    
    <item>
      <title>Python &#43; OAuth</title>
      <link>/2013/10/25/python-oauth/</link>
      <pubDate>Fri, 25 Oct 2013 09:02:51 +0000</pubDate>
      
      <guid>/2013/10/25/python-oauth/</guid>
      <description>As part of a current project I had the misfortune of having to to deal with a bunch of OAuth authenticated web services using a command line script in Python. Usually this isn&amp;rsquo;t really a problem as most decent client libraries for services such as Twitter or Foursquare can handle the authentication requests themselves, usually wrapping their own internal OAuth implementation. However, when it comes to web services that don&amp;rsquo;t have existing python client libraries, you have to do the implementation yourself.</description>
    </item>
    
    <item>
      <title>SWN Festival 2013 plans â€“ part 1: the data (2!)</title>
      <link>/2013/08/18/swn-festival-2013-plans-part-1-the-data-2/</link>
      <pubDate>Sun, 18 Aug 2013 11:36:21 +0000</pubDate>
      
      <guid>/2013/08/18/swn-festival-2013-plans-part-1-the-data-2/</guid>
      <description>In the previous post, I used python and BeautifulSoup to grab the list of artists appearing at SWN Festival 2013, and to scrape their associated soundcloud/twitter/facebook/youtube links (where available).
However, there are more places to find music online than just those listed on the festival site, and some of those extra sources include additional data that I want to collect, so now we need to search these other sources for the artists.</description>
    </item>
    
  </channel>
</rss>