<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><title>More Augmented Conversation</title><meta name=description content="I am Dr Martin Chorley. I am a lecturer at the School of Computer Science & Informatics, Cardiff University.I'm programme leader for the MSc in Computational Journalism, and also senior personal tutor for all taught postgraduate students. I mainly do work that falls under the umbrella of the Mobile and Social Computing group.
"><link rel=icon href=/img/favicon.png><link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" rel=stylesheet type=text/css><link rel=stylesheet type=text/css href=/css/main.css></head><body><div class=wrapper><div class=post><a class=post__back href=/ >&lt;-- back</a><h1 class=post__title>More Augmented Conversation</h1><p class=post__date>August 4, 2011</p><div class=post__content ?><p>Another update on the summer project? Already? Yes.</p><p>The project is really cracking on. We’re two weeks from the end and beginning to see the results roll in, every meeting brings a new version of the software with more functionality. Nick has successfully written a nice framework that allows us to input conversations and automatically retrieve search results based on the topics of those conversations. Even the voice input works (almost) and we’ve got enough time to try and move on to some content extraction ideas. I’ve now written a script to do some automatic evaluation and we’re in a position to subject the attendees of next week’s mobisoc meeting to a human evaluation, which I’m sure will be fun for all concerned.</p><p>There’s some screenshots of the app working below so you can get a flavour of what we’re working on:</p><p>[gallery link=”file”]</p></div></div></div></body></html>