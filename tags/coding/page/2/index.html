<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#b100b2">
    <meta name="theme-color" content="#b100b2">

    <meta property="og:url" content="https://martinjc.com/">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Martin Chorley">
    <meta property="og:site_name" content="Martin Chorley">
    <meta property="og:locale" content="en_GB">
    <meta property="article:author" content="Martin Chorley">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:creator" content="@martinjc">
    <meta name="twitter:url" content="https://martinjc.com">
    <meta name="twitter:title" content="Martin Chorley">

    <link rel="icon" href="/img/favicon.png">
    <link href="https://fonts.googleapis.com/css?family=Roboto|Scope+One" rel="stylesheet">
    <link rel="stylesheet" href="/css/main.css">
</head><body><header>
    <div class="social">
        <ul>
            <li><a href="https://www.twitter.com/martinjc" class="icon twitter" title="Twitter"><svg viewBox="0 0 512 512">
                        <path d="M419.6 168.6c-11.7 5.2-24.2 8.7-37.4 10.2 13.4-8.1 23.8-20.8 28.6-36 -12.6 7.5-26.5 12.9-41.3 15.8 -11.9-12.6-28.8-20.6-47.5-20.6 -42 0-72.9 39.2-63.4 79.9 -54.1-2.7-102.1-28.6-134.2-68 -17 29.2-8.8 67.5 20.1 86.9 -10.7-0.3-20.7-3.3-29.5-8.1 -0.7 30.2 20.9 58.4 52.2 64.6 -9.2 2.5-19.2 3.1-29.4 1.1 8.3 25.9 32.3 44.7 60.8 45.2 -27.4 21.4-61.8 31-96.4 27 28.8 18.5 63 29.2 99.8 29.2 120.8 0 189.1-102.1 185-193.6C399.9 193.1 410.9 181.7 419.6 168.6z" /></svg>
                    </a></li>
            <li><a href="mailto:ChorleyMJ@Cardiff.ac.uk" class="icon email" title="Email"><svg viewBox="0 0 512 512">
                        <path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z" /></svg>
                    </a></li>
            <li><a href="https://www.facebook.com/martin.chorley" class="icon facebook" title="Facebook"><svg viewBox="0 0 512 512">
                        <path d="M211.9 197.4h-36.7v59.9h36.7V433.1h70.5V256.5h49.2l5.2-59.1h-54.4c0 0 0-22.1 0-33.7 0-13.9 2.8-19.5 16.3-19.5 10.9 0 38.2 0 38.2 0V82.9c0 0-40.2 0-48.8 0 -52.5 0-76.1 23.1-76.1 67.3C211.9 188.8 211.9 197.4 211.9 197.4z" /></svg>
                    </a></li>
            <li><a href="https://www.github.com/martinjc" class="icon github" title="GitHub"><svg viewBox="0 0 512 512">
                        <path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z" /></svg>
                    </a></li>
            <li><a href="https://www.instagram.com/martinjam" class="icon instagram" title="Instagram"><svg viewBox="0 0 512 512">
                        <g>
                            <path d="M256 109.3c47.8 0 53.4 0.2 72.3 1 17.4 0.8 26.9 3.7 33.2 6.2 8.4 3.2 14.3 7.1 20.6 13.4 6.3 6.3 10.1 12.2 13.4 20.6 2.5 6.3 5.4 15.8 6.2 33.2 0.9 18.9 1 24.5 1 72.3s-0.2 53.4-1 72.3c-0.8 17.4-3.7 26.9-6.2 33.2 -3.2 8.4-7.1 14.3-13.4 20.6 -6.3 6.3-12.2 10.1-20.6 13.4 -6.3 2.5-15.8 5.4-33.2 6.2 -18.9 0.9-24.5 1-72.3 1s-53.4-0.2-72.3-1c-17.4-0.8-26.9-3.7-33.2-6.2 -8.4-3.2-14.3-7.1-20.6-13.4 -6.3-6.3-10.1-12.2-13.4-20.6 -2.5-6.3-5.4-15.8-6.2-33.2 -0.9-18.9-1-24.5-1-72.3s0.2-53.4 1-72.3c0.8-17.4 3.7-26.9 6.2-33.2 3.2-8.4 7.1-14.3 13.4-20.6 6.3-6.3 12.2-10.1 20.6-13.4 6.3-2.5 15.8-5.4 33.2-6.2C202.6 109.5 208.2 109.3 256 109.3M256 77.1c-48.6 0-54.7 0.2-73.8 1.1 -19 0.9-32.1 3.9-43.4 8.3 -11.8 4.6-21.7 10.7-31.7 20.6 -9.9 9.9-16.1 19.9-20.6 31.7 -4.4 11.4-7.4 24.4-8.3 43.4 -0.9 19.1-1.1 25.2-1.1 73.8 0 48.6 0.2 54.7 1.1 73.8 0.9 19 3.9 32.1 8.3 43.4 4.6 11.8 10.7 21.7 20.6 31.7 9.9 9.9 19.9 16.1 31.7 20.6 11.4 4.4 24.4 7.4 43.4 8.3 19.1 0.9 25.2 1.1 73.8 1.1s54.7-0.2 73.8-1.1c19-0.9 32.1-3.9 43.4-8.3 11.8-4.6 21.7-10.7 31.7-20.6 9.9-9.9 16.1-19.9 20.6-31.7 4.4-11.4 7.4-24.4 8.3-43.4 0.9-19.1 1.1-25.2 1.1-73.8s-0.2-54.7-1.1-73.8c-0.9-19-3.9-32.1-8.3-43.4 -4.6-11.8-10.7-21.7-20.6-31.7 -9.9-9.9-19.9-16.1-31.7-20.6 -11.4-4.4-24.4-7.4-43.4-8.3C310.7 77.3 304.6 77.1 256 77.1L256 77.1z" />
                            <path d="M256 164.1c-50.7 0-91.9 41.1-91.9 91.9s41.1 91.9 91.9 91.9 91.9-41.1 91.9-91.9S306.7 164.1 256 164.1zM256 315.6c-32.9 0-59.6-26.7-59.6-59.6s26.7-59.6 59.6-59.6 59.6 26.7 59.6 59.6S288.9 315.6 256 315.6z" />
                            <circle cx="351.5" cy="160.5" r="21.5" />
                        </g>
                    </svg>
                    </a></li>
            <li><a href="https://www.last.fm/user/takitomouse" class="icon lastfm" title="Last.fm"><svg viewBox="0 0 512 512">
                        <path d="M230.104 336.568l-13.607-36.988c0 0-22.11 24.66-55.268 24.66 -29.341 0-50.172-25.512-50.172-66.328 0-52.293 26.359-71.001 52.297-71.001 37.412 0 49.316 24.234 59.522 55.273l13.607 42.518c13.603 41.236 39.113 74.402 112.666 74.402 52.727 0 88.437-16.155 88.437-58.672 0-34.438-19.56-52.297-56.125-60.802l-27.209-5.951c-18.707-4.252-24.233-11.906-24.233-24.659 0-14.456 11.478-22.96 30.189-22.96 20.406 0 31.458 7.653 33.162 25.935l42.516-5.103c-3.402-38.263-29.761-53.996-73.127-53.996 -38.266 0-75.68 14.456-75.68 60.799 0 28.912 14.029 47.197 49.315 55.697l28.916 6.801c21.683 5.104 28.908 14.031 28.908 26.363 0 15.73-15.305 22.107-44.218 22.107 -42.941 0-60.794-22.534-70.999-53.574l-14.032-42.513c-17.854-55.271-46.342-75.68-102.892-75.68 -62.499-0.001-95.663 39.538-95.663 106.715 0 64.628 33.164 99.489 92.689 99.489C207.141 359.1 230.104 336.568 230.104 336.568L230.104 336.568z" /></svg>
                    </a></li>
            <li><a href="https://uk.linkedin.com/in/martinchorley" class="icon linkedin" title="LinkedIn"><svg viewBox="0 0 512 512">
                        <path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z" /></svg>
                    </a></li>
        </ul>
    </div>


    <nav>
        <ul>|
            <li><a href="/">&nbsp;home</a>&nbsp;|</li>
            <li><a href="/blog">&nbsp;blog</a>&nbsp;|</li>
            <li><a href="/teaching">&nbsp;teaching</a>&nbsp;|</li>
            <li><a href="/research">&nbsp;research</a>&nbsp;|</li>
            <li><a href="/publications">&nbsp;publications</a>&nbsp;|</li>
        </ul>
    </nav>
</header><div id="content">
<main>
    

<ul class="pagination">
    
    <li class="page-item">
        <a href="/tags/coding/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item">
    <a href="/tags/coding/" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/tags/coding/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/page/4/">4</a></li>
    
    
    <li class="page-item">
    <a href="/tags/coding/page/3/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/tags/coding/page/4/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

    
    <article class="blogpost">
        <header>
            <h1> <a href="/2014/08/01/foursquare-icon-downloading-yet-again/">
                    Foursquare icon downloading (yet again)
                </a></h1>
            <p class="author">
                <span class="date">Friday, Aug 1, 2014</span>
            </p>
        </header>
        <div class="content">
            <p><a href="/2011/10/01/colourful-foursquare-category-icons/">Previously</a> I&rsquo;ve<a href="/2012/01/31/foursquare-category-icon-downloader-2/"> written</a> about a little script to download all the category icons from Foursquare and to create many different coloured versions of them. I&rsquo;ve recently had to do this again for a project, and found my previous script did not work with a recent API version. I&rsquo;ve updated the script to fix it and put it up on <a href="https://github.com/martinjc/foursquare_icons">github</a>.</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2014/04/15/msc-computational-journalism-about-to-launch/">
                    MSc Computational Journalism about to launch
                </a></h1>
            <p class="author">
                <span class="date">Tuesday, Apr 15, 2014</span>
            </p>
        </header>
        <div class="content">
            <p>For the last two years I&rsquo;ve been working on a project with some colleagues in the school of Journalism, Media and Cultural Studies (JOMEC) here at Cardiff University and it&rsquo;s finally all coming together. This week we&rsquo;ve been able to <a href="http://www.jomec.co.uk/blog/what-is-computational-journalism/">announce</a> that (subject to some final internal paperwork wrangling) we&rsquo;ll be launching an MSc in Computational Journalism this September. The story of how the course came about is fairly long, but starts simply with a tweet (unfortunately missing the context, but you get the drift):</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/martinjc">@martinjc</a> Just avoided that *shudders* you in work next week. Want to pick your brains on something</p>&mdash; Glyn Mottershead (@egrommet) <a href="https://twitter.com/egrommet/status/226323512086904832">July 20, 2012</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

An offer via social media from someone I'd never met, asking to pick my brains  about an unknown topic. Of course, I jumped at the invite:

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr"><a href="https://twitter.com/egrommet">@egrommet</a> worst freebie ever! Yeah, I&#39;m in all week and pretty free (except thurs). When/where?</p>&mdash; Martin Chorley (@martinjc) <a href="https://twitter.com/martinjc/status/226331942407241729">July 20, 2012</a></blockquote>

<p>That &lsquo;brain picking&rsquo; became an interesting chat over coffee in one of the <a href="https://www.facebook.com/pages/Coffee-Barker/147298511987541">excellent coffee shops in Cardiff</a>, where <a href="http://www.cardiff.ac.uk/jomec/contactsandpeople/profiles/mottershead-glyn.html">Glyn</a> and I discussed many things of interest, and many potential areas for collaboration - including the increased use of data and coding within modern journalism. At one point during this chat, m&rsquo;colleague <a href="http://www.cardiff.ac.uk/jomec/contactsandpeople/profiles/mottershead-glyn.html">Glyn</a> said something like &ldquo;do you know, I think we should run a masters course on this.&rdquo; I replied with something along the lines of &ldquo;yes, I think that&rsquo;s a very good idea.&rdquo; That short conversation became us taking the idea of a MSc in Computational Journalism to our respective heads of schools, which became us sat around the table discussing what should be in such a course, which then became us (I say us, it was mainly all <a href="http://www.cardiff.ac.uk/jomec/contactsandpeople/profiles/sambrook-richard.html">Richard</a>) writing pages of documentation explaining what the course would be and arguing the case for it to the University.  Last week we held the final approval panel for the course, where both internal and external panel members all agreed that we pretty much knew what we were doing, that the course was a good idea and had the right content, and that we should go ahead and launch it. From 25th July 2012 to 1st April 2014 is a long time to get an MSc up and running, but we&rsquo;ve finally done it. Over that time I&rsquo;ve discovered many things about the University and its processes, drunk many pints of fine ale as we try to hammer out a course structure in various pubs around the city, and have come close on at least one occasion to screaming at a table full of people, but now it&rsquo;s done. As I write, draft press releases are being written, budgets are being sorted, and details are being uploaded to coursefinder. With any luck, September will see us with a batch of students ready and willing to step onto the course for the first time. It&rsquo;s exciting, and I can&rsquo;t wait.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">New MSc in Computational Journalism from <a href="https://twitter.com/CardiffJomec">@CardiffJomec</a> and @csicardiff going ahead. Details to follow full approval - launch in the autumn</p>&mdash; Richard Sambrook (@sambrook) <a href="https://twitter.com/sambrook/status/451713389556154368">April 3, 2014</a></blockquote>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Journalism and computer science, you say? In Cardiff? With <a href="https://twitter.com/sambrook">@sambrook</a>, me and <a href="https://twitter.com/martinjc">@martinjc</a>? <a href="http://t.co/IBnovbafWK">http://t.co/IBnovbafWK</a></p>&mdash; Glyn Mottershead (@egrommet) <a href="https://twitter.com/egrommet/status/456091706983997441">April 15, 2014</a></blockquote>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/10/25/python-oauth/">
                    Python &#43; OAuth
                </a></h1>
            <p class="author">
                <span class="date">Friday, Oct 25, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>As part of a current project I had the misfortune of having to to deal with a bunch of OAuth authenticated web services using a command line script in Python. Usually this isn&rsquo;t really a problem as most decent client libraries for services such as <a href="https://github.com/tweepy/tweepy">Twitter</a> or <a href="https://pypi.python.org/pypi/foursquare">Foursquare</a> can handle the authentication requests themselves, usually wrapping their own internal OAuth implementation. However, when it comes to web services that don&rsquo;t have existing python client libraries, you have to do the implementation yourself. Unfortunately support for OAuth in Python is a mess, so this is not the most pleasant of tasks, especially when most stackoverflow <a href="http://stackoverflow.com/questions/12628246/how-to-send-oauth-request-with-python-oauth2">posts</a> <a href="http://stackoverflow.com/questions/15610749/github-api-v3-access-via-python-oauth2-library-redirect-issue">on</a> <a href="http://stackoverflow.com/questions/1666415/python-oauth-library">the</a> topic point to massively <a href="http://code.daaku.org/python-oauth/">outdated</a> and <a href="https://github.com/simplegeo/python-oauth2">unmaintained</a> Python libraries.</p>

<p>Fortunately after some digging around, I was able to find a nice, well maintained and <a href="https://rauth.readthedocs.org/en/latest/">fairly well documented</a> solution: <a href="https://github.com/litl/rauth">rauth</a>, which is very clean and easy to use. As an example, I was trying to connect to the Fitbit API, and it really was as simple as following their example.</p>

<p>Firstly, we create an OAuth1Service:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> rauth
<span style="color:#f92672">from</span> _credentials <span style="color:#f92672">import</span> consumer_key, consumer_secret

base_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://api.fitbit.com&#34;</span>
request_token_url <span style="color:#f92672">=</span> base_url <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/oauth/request_token&#34;</span>
access_token_url <span style="color:#f92672">=</span> base_url <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/oauth/access_token&#34;</span>
authorize_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://www.fitbit.com/oauth/authorize&#34;</span>

fitbit <span style="color:#f92672">=</span> rauth<span style="color:#f92672">.</span>OAuth1Service(
 name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;fitbit&#34;</span>,
 consumer_key<span style="color:#f92672">=</span>consumer_key,
 consumer_secret<span style="color:#f92672">=</span>consumer_secret,
 request_token_url<span style="color:#f92672">=</span>request_token_url,
 access_token_url<span style="color:#f92672">=</span>access_token_url,
 authorize_url<span style="color:#f92672">=</span>authorize_url,
 base_url<span style="color:#f92672">=</span>base_url)</code></pre></div>

<p>Then we get the temporary request token credentials:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">request_token, request_token_secret <span style="color:#f92672">=</span> fitbit<span style="color:#f92672">.</span>get_request_token()

<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34; request_token = </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> request_token
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34; request_token_secret = </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> request_token_secret
<span style="color:#66d9ef">print</span></code></pre></div>

<p>We then ask the user to authorise our application, and give us the PIN so we can prove to the service that they authorised us:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">authorize_url <span style="color:#f92672">=</span> fitbit<span style="color:#f92672">.</span>get_authorize_url(request_token)

<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;Go to the following page in your browser: &#34;</span> <span style="color:#f92672">+</span> authorize_url
<span style="color:#66d9ef">print</span>

accepted <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;n&#39;</span>
<span style="color:#66d9ef">while</span> accepted<span style="color:#f92672">.</span>lower() <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;n&#39;</span>:
 accepted <span style="color:#f92672">=</span> raw_input(<span style="color:#e6db74">&#39;Have you authorized me? (y/n) &#39;</span>)
pin <span style="color:#f92672">=</span> raw_input(<span style="color:#e6db74">&#39;Enter PIN from browser &#39;</span>)</code></pre></div>

<p>Finally, we can create an authenticated session and access user data from the service:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">session <span style="color:#f92672">=</span> fitbit<span style="color:#f92672">.</span>get_auth_session(request_token,
 request_token_secret,
 method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;POST&#34;</span>,
 data<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;oauth_verifier&#39;</span>: pin})

<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;&#34;</span>
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34; access_token = </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> session<span style="color:#f92672">.</span>access_token
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34; access_token_secret = </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> session<span style="color:#f92672">.</span>access_token_secret
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;&#34;</span>

url <span style="color:#f92672">=</span> base_url <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/1/&#34;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;user/-/profile.json&#34;</span>

r <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get(url, params<span style="color:#f92672">=</span>{}, header_auth<span style="color:#f92672">=</span>True)
<span style="color:#66d9ef">print</span> r<span style="color:#f92672">.</span>json()</code></pre></div>

<p>It really is that easy to perform a 3-legged OAuth authentication on the command line. If you&rsquo;re only interested in data from 1 user, and you want to run the app multiple times, once you have the access token and secret, there&rsquo;s nothing to stop you just storing those and re-creating your session each time without having to re-authenticate (assuming the service does not expire access tokens):</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">base_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://api.fitbit.com/&#34;</span>
api_version <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1/&#34;</span>
token <span style="color:#f92672">=</span> (fitbit_oauth_token, fitbit_oauth_secret)
consumer <span style="color:#f92672">=</span> (fitbit_consumer_key, fitbit_consumer_secret)

session <span style="color:#f92672">=</span> rauth<span style="color:#f92672">.</span>OAuth1Session(consumer[<span style="color:#ae81ff">0</span>], consumer[<span style="color:#ae81ff">1</span>], token[<span style="color:#ae81ff">0</span>], token[<span style="color:#ae81ff">1</span>])
url <span style="color:#f92672">=</span> base_url <span style="color:#f92672">+</span> api_version <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;user/-/profile.json&#34;</span>
r <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>get(url, params<span style="color:#f92672">=</span>{}, header_auth<span style="color:#f92672">=</span>True)
<span style="color:#66d9ef">print</span> r<span style="color:#f92672">.</span>json()</code></pre></div>

<p>So there we have it. Simple OAuth authentication on the command line, in Python. As always, the code is available on <a href="https://github.com/martinjc/rauth---fitbit-example">github</a> if you&rsquo;re interested.</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/09/24/ksri-services-summer-school-social-computing-theory-and-hackathon/">
                    KSRI Services Summer School - Social Computing Theory and Hackathon
                </a></h1>
            <p class="author">
                <span class="date">Tuesday, Sep 24, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>I was invited by <a href="http://www.ksri.kit.edu/Default.aspx?PageId=691&amp;lang=en">Simon Caton</a> to come to the <a href="http://www.ksri.kit.edu/Default.aspx?lang=en">KSRI</a> <a href="http://service-summer.ksri.kit.edu/62.php">Services Summer School</a>, held at <a href="http://www.kit.edu/index.php">KIT</a> in Germany, to help him run a workshop session on <a href="http://service-summer.ksri.kit.edu/104.php">Social Computing</a>.  We decided to use the session as a crash course in retrieving and manipulating data from Social Media APIs - showing the students the basics, then running a mini &lsquo;hackathon&rsquo; for the students to gain some practical experience.</p>

<p>I think the session went really well, the students seemed to enjoy it and the feedback was very positive. We spent about 90 minutes talking about APIs, JSON, Twitter, Facebook and Foursquare, then set the students off on forming teams and brainstorming ideas. Very quickly they managed to get set up grabbing Twitter data from the streaming API, and coming up with ways of analysing it for interesting facts and statistics.  A number of the students were not coders, and had never done anything like this before, so it was great to see them diving in, setting up servers and running php scripts to grab the data. It was also good to see the level of team work on display; everyone was communicating, dividing the work, and getting on well. Fuelled by a combination of pizza, beer, red bull and haribo they coded into the night, until we drew things to a close at about 10pm and retired to the nearest bar for a pint of debrief.</p>










<figure>
    <img src="/2013/09/24/ksri-services-summer-school-social-computing-theory-and-hackathon/2013-09-23-18.03.23-1024x768.jpg" width="1024" height="768" alt="Hackathon Students">
    <figcaption>
        <small>
            Hackathon Students
        </small>
    </figcaption>
</figure>

<p>It was a really good experience, and I think everyone got something useful out of it. I&rsquo;m looking forward to the presentations later on today to see what everyone came up with.</p>

<p>Our slides from the talk are available on <a href="http://www.slideshare.net/karlsruheserviceresearchinstitute/social-computing-analysing-social-media-theory-and-hackathon">slideshare</a>. As usual they&rsquo;re information light and picture heavy, so their usefulness is probably limited!</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/08/18/swn-festival-2013-plans-part-1-the-data-2/">
                    SWN Festival 2013 plans – part 1: the data (2!)
                </a></h1>
            <p class="author">
                <span class="date">Sunday, Aug 18, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>In the previous post, I used python and BeautifulSoup to grab the list of artists appearing at <a href="http://www.swnfest.com">SWN Festival 2013</a>, and to scrape their associated soundcloud/twitter/facebook/youtube links (where available).</p>

<p>However, there are more places to find music online than just those listed on the festival site, and some of those extra sources include additional data that I want to collect, so now we need to search these other sources for the artists. Firstly, we need to load the artist data we previously extracted from the festival website, and iterate through the list of artists one by one:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">artists <span style="color:#f92672">=</span> {}
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;bands.json&#34;</span>) <span style="color:#66d9ef">as</span> infile:
    artists <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>load(infile)

<span style="color:#66d9ef">for</span> artist, artist_data <span style="color:#f92672">in</span> artists<span style="color:#f92672">.</span>iteritems():</code></pre></div>

<p>The first thing I want to do for each artist it to search Spotify to see if they have any music available there. Spotify has a simple web <a href="https://developer.spotify.com/technologies/web-api/">API</a> for searching which is pretty straightforward to use:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">params <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#34;q&#34;</span> : <span style="color:#e6db74">&#34;artist:&#34;</span> <span style="color:#f92672">+</span> artist<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;utf-8&#34;</span>)
}

spotify_root_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://ws.spotify.com/search/1/artist.json&#34;</span>
spotify_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">?</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (spotify_root_url, urllib<span style="color:#f92672">.</span>urlencode(params))

data <span style="color:#f92672">=</span> retrieve_json_data(spotify_url)

<span style="color:#66d9ef">if</span> data<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;artists&#34;</span>, None) <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None:
    <span style="color:#66d9ef">if</span> len(data[<span style="color:#e6db74">&#34;artists&#34;</span>]) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
        artist_id <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;artists&#34;</span>][<span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#34;href&#34;</span>]<span style="color:#f92672">.</span>lstrip(<span style="color:#e6db74">&#34;spotify:artist:&#34;</span>)
        artist_data[<span style="color:#e6db74">&#34;spotify_id&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;artists&#34;</span>][<span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#34;href&#34;</span>]
        artist_data[<span style="color:#e6db74">&#34;spotify_url&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://open.spotify.com/artist/&#34;</span> <span style="color:#f92672">+</span> artist_id</code></pre></div>

<p>The &lsquo;retrieve_json_data&rsquo; function is just a wrapper to call a URL and parse the returned JSON data:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">retrieve_json_data</span>(url):

    <span style="color:#66d9ef">try</span>:
        response <span style="color:#f92672">=</span> urllib2<span style="color:#f92672">.</span>urlopen(url)
    <span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>HTTPError, e:
        <span style="color:#66d9ef">raise</span> e
    <span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>URLError, e:
        <span style="color:#66d9ef">raise</span> e

    raw_data <span style="color:#f92672">=</span> response<span style="color:#f92672">.</span>read()
    data <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(raw_data)

    <span style="color:#66d9ef">return</span> data</code></pre></div>

<p>Once I&rsquo;ve searched Spotify, I then want to see if the artist has a page on Last.FM. If they do, I also want to extract and store their top-tags from the site. Again, the Last.FM API makes this straightforward. Firstly, searching for the artist page:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">params <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#34;artist&#34;</span>: artist<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;utf-8&#34;</span>),
    <span style="color:#e6db74">&#34;api_key&#34;</span>: last_fm_api_key,
    <span style="color:#e6db74">&#34;method&#34;</span>: <span style="color:#e6db74">&#34;artist.getinfo&#34;</span>,
    <span style="color:#e6db74">&#34;format&#34;</span>: <span style="color:#e6db74">&#34;json&#34;</span>
}

last_fm_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://ws.audioscrobbler.com/2.0/?&#34;</span> <span style="color:#f92672">+</span> urllib<span style="color:#f92672">.</span>urlencode(params)

data <span style="color:#f92672">=</span> retrieve_json_data(last_fm_url)

<span style="color:#66d9ef">if</span> data<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;artist&#34;</span>, None) <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None:
    <span style="color:#66d9ef">if</span> data[<span style="color:#e6db74">&#34;artist&#34;</span>]<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;url&#34;</span>, None) <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None:
        artist_data[<span style="color:#e6db74">&#34;last_fm_url&#34;</span>] <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;artist&#34;</span>][<span style="color:#e6db74">&#34;url&#34;</span>]</code></pre></div>

<p>Then, searching for the artist&rsquo;s top tags:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">params <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#34;artist&#34;</span>: artist<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;utf-8&#34;</span>),
    <span style="color:#e6db74">&#34;api_key&#34;</span>: last_fm_api_key,
    <span style="color:#e6db74">&#34;method&#34;</span>: <span style="color:#e6db74">&#34;artist.gettoptags&#34;</span>,
    <span style="color:#e6db74">&#34;format&#34;</span>: <span style="color:#e6db74">&#34;json&#34;</span>
}

last_fm_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://ws.audioscrobbler.com/2.0/?&#34;</span> <span style="color:#f92672">+</span> urllib<span style="color:#f92672">.</span>urlencode(params)

data <span style="color:#f92672">=</span> retrieve_json_data(last_fm_url)

<span style="color:#66d9ef">if</span> data<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;toptags&#34;</span>, None) <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None:

    artist_data[<span style="color:#e6db74">&#34;tags&#34;</span>] <span style="color:#f92672">=</span> {}

    <span style="color:#66d9ef">if</span> data[<span style="color:#e6db74">&#34;toptags&#34;</span>]<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;tag&#34;</span>, None) <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> None:
        tags <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#34;toptags&#34;</span>][<span style="color:#e6db74">&#34;tag&#34;</span>]
        <span style="color:#66d9ef">if</span> type(tags) <span style="color:#f92672">==</span> type([]):
            <span style="color:#66d9ef">for</span> tag <span style="color:#f92672">in</span> tags:
                name <span style="color:#f92672">=</span> tag[<span style="color:#e6db74">&#34;name&#34;</span>]<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;utf-8&#39;</span>)
                count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> int(tag[<span style="color:#e6db74">&#34;count&#34;</span>]) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">else</span> int(tag[<span style="color:#e6db74">&#34;count&#34;</span>])
                artist_data[<span style="color:#e6db74">&#34;tags&#34;</span>][name] <span style="color:#f92672">=</span> count
            <span style="color:#66d9ef">else</span>:
                name <span style="color:#f92672">=</span> tags[<span style="color:#e6db74">&#34;name&#34;</span>]<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;utf-8&#39;</span>)
                count <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> int(tags[<span style="color:#e6db74">&#34;count&#34;</span>]) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">else</span> int(tags[<span style="color:#e6db74">&#34;count&#34;</span>])
                artist_data[<span style="color:#e6db74">&#34;tags&#34;</span>][name] <span style="color:#f92672">=</span> count</code></pre></div>

<p>Again, once we&rsquo;ve retrieved all the extra artist data, we can dump it to file:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;bands.json&#34;</span>, <span style="color:#e6db74">&#34;w&#34;</span>) <span style="color:#66d9ef">as</span> outfile:
    json<span style="color:#f92672">.</span>dump(artists, outfile)</code></pre></div>

<p>So, I now have 2 scripts that I can run regularly to capture any updates to the festival website (including lineup additions) and to search for artist data on Spotify and Last.FM. Now I&rsquo;ve got all this data captured and stored, it&rsquo;s time to start doing something interesting with it&hellip;</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/08/14/swn-festival-2013-plans-part-1-the-data/">
                    SWN Festival 2013 plans -  part 1: the data
                </a></h1>
            <p class="author">
                <span class="date">Wednesday, Aug 14, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>As <a href="/2013/08/11/swn-festival-2013-plans/">I mentioned</a>, I&rsquo;m planning on doing a bit more development work this year connected to the <a href="http://www.swnfest.com">SWN Festival</a>. The first stage is to get hold of the data associated with the festival in an accessible and machine readable form so it can be used in other apps.</p>

<p>Unfortunately (but unsurprisingly), being a smallish local festival, there is no API for any of the data. So, getting a list of the bands and their info means we need to resort to web scraping. Fortunately, with a couple of lines of python and the BeautifulSoup library, getting the list of artists playing the festival is pretty straightforward:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> urllib2
<span style="color:#f92672">import</span> json

<span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
root_page <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://swnfest.com/&#34;</span>
lineup_page <span style="color:#f92672">=</span> root_page <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;lineup/&#34;</span>

<span style="color:#66d9ef">try</span>:
    response <span style="color:#f92672">=</span> urllib2<span style="color:#f92672">.</span>urlopen(lineup_page)
<span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>HTTPError, e:
    <span style="color:#66d9ef">raise</span> e
<span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>URLError, e:
    <span style="color:#66d9ef">raise</span> e

raw_data <span style="color:#f92672">=</span> response<span style="color:#f92672">.</span>read()

soup <span style="color:#f92672">=</span> BeautifulSoup(raw_data)

links <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;.artist-listing h5 a&#34;</span>)

artists <span style="color:#f92672">=</span> {}

<span style="color:#66d9ef">for</span> link <span style="color:#f92672">in</span> links:
    url <span style="color:#f92672">=</span> link<span style="color:#f92672">.</span>attrs[<span style="color:#e6db74">&#34;href&#34;</span>]
    artist <span style="color:#f92672">=</span> link<span style="color:#f92672">.</span>contents[<span style="color:#ae81ff">0</span>]

    artists[artist] <span style="color:#f92672">=</span> {}
    artists[artist][<span style="color:#e6db74">&#34;swn_url&#34;</span>] <span style="color:#f92672">=</span> url</code></pre></div>

<p>All we&rsquo;re doing here is loading the <a href="http://swnfest.com/lineup/">lineup</a> page for the main festival website, using BeautifulSoup to find all the links to individual artist pages (which are in a div with a class of &ldquo;artist-listing&rdquo;, each one in a h5 tag), then parsing these links to extract the artist name, and the url of their page on the festival website.</p>

<p>Each artist page on the website includes handy links to soundcloud, twitter, youtube etc (where these exist), and since I&rsquo;m going to want to include these kinds of things in the apps I&rsquo;m working on, I&rsquo;ll grab those too:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> artist, data <span style="color:#f92672">in</span> artists<span style="color:#f92672">.</span>iteritems():
    <span style="color:#66d9ef">try</span>:
        response <span style="color:#f92672">=</span> urllib2<span style="color:#f92672">.</span>urlopen(data[<span style="color:#e6db74">&#34;swn_url&#34;</span>])
    <span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>HTTPError, e:
        <span style="color:#66d9ef">raise</span> e
    <span style="color:#66d9ef">except</span> urllib2<span style="color:#f92672">.</span>URLError, e:
        <span style="color:#66d9ef">raise</span> e

    raw_data <span style="color:#f92672">=</span> response<span style="color:#f92672">.</span>read()

    soup <span style="color:#f92672">=</span> BeautifulSoup(raw_data)

    links <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;.outlinks li&#34;</span>)

    <span style="color:#66d9ef">for</span> link <span style="color:#f92672">in</span> links:
         source_name <span style="color:#f92672">=</span> link<span style="color:#f92672">.</span>attrs[<span style="color:#e6db74">&#34;class&#34;</span>][<span style="color:#ae81ff">0</span>]
         source_url <span style="color:#f92672">=</span> link<span style="color:#f92672">.</span>findChild(<span style="color:#e6db74">&#34;a&#34;</span>)<span style="color:#f92672">.</span>attrs[<span style="color:#e6db74">&#34;href&#34;</span>]
         data[source_name] <span style="color:#f92672">=</span> source_url</code></pre></div>

<p>This code iterates through the list of artists we just extracted from the lineup page, retrieves the relevant artist page, and parses it for the outgoing links, stored in list items in an unordered list with a class of &lsquo;outlinks&rsquo;. Fortunately each link in this list has a class describing what type of link it is (facebook/twitter/soundcloud etc) so we can use the class as a key in our dictionary, with the link itself as an item. Later on once schedule information is included in the artist page we can add some code to parse stage-times and venues, but at the moment that data isn&rsquo;t present on the pages, so we can&rsquo;t extract it yet.</p>

<p>Finally we can just dump our artist data to json, and we have the information we need in an easily accessible format:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;bands.json&#34;</span>, <span style="color:#e6db74">&#34;w&#34;</span>) <span style="color:#66d9ef">as</span> outfile:
    json<span style="color:#f92672">.</span>dump(artists, outfile)</code></pre></div>

<p>Now we have the basic data for each artist, we can go on to search for more information on other music sites. The nice thing about this script is that when the lineup gets updated, we can just re-run the code and capture all the new artists that have been added. I should also mention that all the code I&rsquo;m using for this is available on <a href="https://github.com/martinjc/swnScraper2013">github</a>.</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/08/11/swn-festival-2013-plans/">
                    SWN Festival 2013 - plans
                </a></h1>
            <p class="author">
                <span class="date">Sunday, Aug 11, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>Last year I had a go at creating a couple of web apps based around the bands playing the <a href="http://www.swnfest.com">SWN Festival</a> here in Cardiff. I love SWN with all my heart, it&rsquo;s a permanent fixture in my calendar and even if (when) I leave Cardiff it&rsquo;ll be the one thing I come back for every year. It&rsquo;s a great way to see and discover new bands, but sometimes the sheer volume of music on offer can be overwhelming. So I wanted to see if I could create some web apps that would help to navigate your way through all the bands, and find the ones that you should go and see.</p>

<p>The <a href="/swn/2012/tags/">first</a> was a simple app that gathered artist tags from Last.FM, allowing you to see which artists playing the festival had similar tags - so if you knew you liked one artist you could find other artists tagged with the same terms. The <a href="/swn/2012/rec/">second</a> (which technically wasn&rsquo;t ever really finished) would allow you to login with a last.fm account and find the artists whose tags best matched the tags for your top artists in your last.fm profile.</p>

<p>I liked both these apps and found them both useful - but I don&rsquo;t think they went far enough. I only started development late in the year, about a month before the festival, so didn&rsquo;t have a lot of time to really get into it. This year I&rsquo;m starting a lot earlier, so I&rsquo;ve got time to do a lot more.</p>

<p>Firstly I&rsquo;d like to repeat the apps from last year, but perhaps combining them in some way. I&rsquo;d like to include more links to the actual music, making it easy to get from an artist to their songs by including embeds from soundcloud, spotify, youtube etc. I&rsquo;d also like to try making a mobile app guide to the festival (probably as an android app as the official app is iOS only). I&rsquo;m hopeful that given enough free time I should be able to get some genuinely useful stuff done, and I&rsquo;ll be blogging about it here as I work on it.</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/07/25/summer-project-update/">
                    Summer Project update
                </a></h1>
            <p class="author">
                <span class="date">Thursday, Jul 25, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>We are storming along with <a href="/research/student-projects/">summer projects</a> now, and starting to see some really good results.</p>

<p>Liam Turner (who is starting a PhD in the school in October) has been working hard to create a mobile version of the <a href="http://www.cs.cf.ac.uk/recognition/foursqexp/">4SQPersonality</a> app. His work is coming along really well, with a great mobile HTML version now up and running, a native android wrapper working, and an iOS wrapper on its way. With any luck we&rsquo;ll have mobile apps for both major platforms ready to be released before the summer is over.</p>

<p>Max Chandler, who is now a second year undergraduate, has done some great work looking at the Foursquare venues within various cities around the UK, analysing them for similarity and spatial distribution. He&rsquo;s just over halfway through the project now and is beginning to work on visualising the data he&rsquo;s collected and analysed. He&rsquo;s creating some interesting interactive visualisations using <a href="http://d3js.org/">D3</a>, so as soon as he&rsquo;s done I&rsquo;ll link to the website here.</p>

<p>It&rsquo;s been a really good summer for student projects so far, with some really pleasing results. I&rsquo;ll post more description of the projects and share some of the results as they come to a close in the coming weeks.</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/04/22/open-sauce-hackathon-post-mortem/">
                    Open Sauce Hackathon - Post Mortem
                </a></h1>
            <p class="author">
                <span class="date">Monday, Apr 22, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>This weekend saw the second &lsquo;<a href="http://www.cs.cf.ac.uk/hackathon/">Open Sauce Hackathon</a>&rsquo; run by undergraduate students here in the school. Last years was pretty successful, and they improved upon it this year, pulling in many more sponsors and offering more prizes.</p>

<p>Unlike last year, when I turned up having already decided with Jon Quinn what we were doing, I went along this year with no real ideas. I had a desire to do something with a map, as I&rsquo;m pretty sure building stuff connected to maps is going to play a big part in work over the next couple of months. Other than that though, I was at a bit of a loss. After playing around with some ideas and APIs I finally came up with my app: <a href="/dionysus/">dionysus</a>.</p>

<p><img src="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/Screen-Shot-2013-04-22-at-11.37.57.png" alt="Dionysus Screenshot" /></p>

<p>It&rsquo;s a mobile friendly mapping app that shows you two important things: Where the pubs are (using venue data from <a href="http://www.foursquare.com">Foursquare</a>) and where the gigs are at (using event data from <a href="http://www.last.fm">last.fm</a>). If you sign in to either last.fm or Foursquare it will also pull in recommended bars and recommended gigs and highlight these for you.</p>

<p>The mapping is done using <a href="http://leafletjs.com/">leaflet.js</a>, which I found to be nicer and easier to use than Google Maps. The map tiles are based on <a href="http://www.openstreetmap.org/">OpenStreetMap</a> data and come from <a href="http://cloudmade.com/">CloudMade</a>, while the (devastatingly beautiful) icons were rushed together by me over the weekend. The entire app is just client side Javascript and HTML, with HTML5 persistent localStorage used to maintain login authentication between sessions. It&rsquo;s a simple app, but I&rsquo;m pretty pleased with it. In the end I even won a prize for it (£50), so it can&rsquo;t be too bad.</p>

<p>The app is hosted <a href="/dionysus/">here</a>, and the source code is available <a href="https://github.com/martinjc/dionysus">here</a>. Obviously though the code is not very pretty and quite hacky, but it does the job!</p>

        </div>
    </article>
    
    <article class="blogpost">
        <header>
            <h1> <a href="/2013/03/15/advanced-latex-course/">
                    Advanced LaTeX Course
                </a></h1>
            <p class="author">
                <span class="date">Friday, Mar 15, 2013</span>
            </p>
        </header>
        <div class="content">
            <p>Here are the slides and source code for the UGC Advanced LaTeX course, 15th March 2013</p>

<p>Introduction (Beginners Recap, Graphics &amp; Figures) - <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/introduction.pdf">handouts</a> and <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/introduction.zip">source
</a>BibTeX and Referencing - <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/bibtex.pdf">handouts</a> &amp; <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/bibtex.zip">source
</a>Custom Commands &amp; Environments, Source Code Listings, Tips &amp; Tricks - <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/custom.pdf">handouts</a> &amp; <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/custom.zip">source
</a>Exercise Sheets - <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/exercise_handouts.zip">handouts</a> &amp; <a href="/img/{{ page.date | date: &quot;%Y-%m-%d&quot;}}-{{page.slug}}/exercises.zip">source</a></p>

        </div>
    </article>
    
    

<ul class="pagination">
    
    <li class="page-item">
        <a href="/tags/coding/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item">
    <a href="/tags/coding/" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/tags/coding/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/tags/coding/page/4/">4</a></li>
    
    
    <li class="page-item">
    <a href="/tags/coding/page/3/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/tags/coding/page/4/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

</main>

    </div><script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-25500481-1', 'auto');
    ga('send', 'pageview');

</script>
<script>window.twttr = (function (d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0],
            t = window.twttr || {};
        if (d.getElementById(id)) return t;
        js = d.createElement(s);
        js.id = id;
        js.src = "https://platform.twitter.com/widgets.js";
        fjs.parentNode.insertBefore(js, fjs);

        t._e = [];
        t.ready = function (f) {
            t._e.push(f);
        };

        return t;
    }(document, "script", "twitter-wjs"));
</script></body>

</html>